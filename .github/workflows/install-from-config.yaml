# In this workflow, we install dependencies from a requirements.txt within an ubuntu based OS
name: Install from config

# Controls when the workflow will run
on:

  workflow_dispatch:
  # Allows you to run this workflow manually from the Actions tab
  # A workflow run is made up of one or more jobs that can run sequentially or in parallel

jobs:
  pipeline:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    if: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID.passed }} == true
    env:
      
      AWS_ACCESS_KEY_ID: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID  || secrets.AWS_ACCESS_KEY_ID}}
    
      GITHUB_REPO: ${{ github.event.client_payload.REPO || secrets.REPO }}
      GITHUB_ORG: ${{ github.event.client_payload.ORG || secrets.ORG }}

      S3_ENDPOINT_URL: ${{ secrets.S3_ENDPOINT_URL }}
      S3_BUCKET: ${{ secrets.S3_BUCKET }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}

      CEPH_BUCKET: ${{ secrets.CEPH_BUCKET }}
      CEPH_BUCKET_PREFIX: ${{ secrets.CEPH_BUCKET_PREFIX }}
      CEPH_KEY_ID: ${{ secrets.CEPH_KEY_ID }}
      CEPH_SECRET_KEY: ${{ secrets.CEPH_SECRET_KEY }}

      GITHUB_ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN }}
      
      REMOTE: 1
      CHOSEN_MODEL: 'rf'

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - name: Checkout repo
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9'
          
      - name: Install xmllint
        run: sudo apt-get install build-essential libffi-dev python3 python3-dev python3-pip libfuzzy-dev
          
      - name: Install dependencies
        run: python -m pip install --upgrade pip -r requirements.txt

      - name: Data Collection notebook
        run: |
          python -m pip install jupyter nbconvert nbformat
          jupyter nbconvert --to notebook --execute 01_data_collection.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 01_notebook_executed
      - name: commit updated notebook
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook"
          add: "01_notebook_executed.ipynb"
      - name: Feature Engineering notebook
        run: |
          python -m pip install jupyter nbconvert nbformat
          jupyter nbconvert --to notebook --execute 02_feature_engineering.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 02_notebook_executed
      - name: commit updated notebook 2
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 2"
          add: "02_notebook_executed.ipynb"
      - name: Model Training notebook
        run: |
          python -m pip install jupyter nbconvert nbformat
          jupyter nbconvert --to notebook --execute 03_model_training.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 03_notebook_executed
      - name: commit updated notebook 3
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 3"
          add: "03_notebook_executed.ipynb"
      - name: Model Inference notebook
        run: jupyter nbconvert --to notebook --execute 04_model_inference.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 04_notebook_executed
      - name: commit updated notebook 4
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Update Notebook 4"
          add: "04_notebook_executed.ipynb"
