# We run this workflow on the base ocp-ci-analysis container image which contains dependencies neccesary to run these notebooks 
name: Run in container

# Controls when the workflow will run
on:

  repository_dispatch:
  # Allows submitting to this workflow using client payload
  workflow_dispatch:
  # Allows you to run this workflow manually from the Actions tab
  # A workflow run is made up of one or more jobs that can run sequentially or in parallel

jobs:
  pipeline:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    container: 
      image: quay.io/aicoe/ocp-ci-analysis
    if: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID.passed }} == true
    env:
      
      AWS_ACCESS_KEY_ID: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID  || secrets.AWS_ACCESS_KEY_ID}}
    
      GITHUB_REPO: ${{ github.event.client_payload.REPO || secrets.REPO }}
      GITHUB_ORG: ${{ github.event.client_payload.ORG || secrets.ORG }}

      S3_ENDPOINT_URL: ${{ github.event.client_payload.S3_ENDPOINT_URL || secrets.S3_ENDPOINT_URL }}
      S3_BUCKET: ${{ github.event.client_payload.S3_BUCKET || secrets.S3_BUCKET }}
      AWS_SECRET_ACCESS_KEY: ${{ github.event.client_payload.AWS_SECRET_ACCESS_KEY || secrets.AWS_SECRET_ACCESS_KEY }}

      CEPH_BUCKET: ${{ github.event.client_payload.S3_BUCKET || secrets.S3_BUCKET }}
      CEPH_BUCKET_PREFIX: ${{ github.event.client_payload.PREFIX|| secrets.CEPH_BUCKET_PREFIX }}
      CEPH_KEY_ID: ${{ github.event.client_payload.AWS_ACCESS_KEY_ID  || secrets.AWS_ACCESS_KEY_ID }}
      CEPH_SECRET_KEY: ${{ github.event.client_payload.AWS_SECRET_ACCESS_KEY || secrets.AWS_SECRET_ACCESS_KEY }}

      GITHUB_ACCESS_TOKEN: ${{ secrets.ACCESS_TOKEN || secrets.GITHUB_TOKEN }}
      
      REMOTE: 1

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - name: Checkout repo
        uses: actions/checkout@v2
        
      - name: Run data collection
        run: python 01_data_collection.py
      - name: Feature Engineering notebook
        run: jupyter nbconvert --to notebook --execute 02_feature_engineering.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 02_notebook_executed
      - name: commit updated notebook 2
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Updated feature engineering"
          add: "02_notebook_executed.ipynb"
      - name: Model Training notebook
        run: jupyter nbconvert --to notebook --execute 03_model_training.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 03_notebook_executed
      - name: commit updated notebook 3
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Updated training"
          add: "03_notebook_executed.ipynb"
      - name: Model Inference notebook
        run: jupyter nbconvert --to notebook --execute 04_model_inference.ipynb --TemplateExporter.exclude_input=True --ExecutePreprocessor.kernel_name='python3' --output 04_notebook_executed
      - name: commit updated notebook 4
        uses: EndBug/add-and-commit@v7
        with:
          author_name: update notebook with pipeline
          message: "Updated inference"
          add: "04_notebook_executed.ipynb" 
